{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de Fraude en Transacciones de Tarjetas de Crédito\n",
    "El conjunto de datos de este problema comprende transacciones realizadas mediante tarjetas de crédito en un lapso de dos días, contabilizando 492 casos de fraude entre un total de 284,807 transacciones. Este dataset presenta un desequilibrio considerable, ya que la clase positiva (fraude) representa solo el 0.17 % del total de transacciones. Para una descripción más detallada del dataset, consulte el archivo credit card description.md.\n",
    "En este problema, nuestro objetivo es desarrollar varios modelos para clasificar una transacción como fraudulenta o no, y luego evaluar la eficacia de cada uno. Para esto, el conjunto de datos se dividió previamente en uno de entrenamiento (credit card train.csv ), uno de validaci ́on (credit card valid.csv) y uno de testeo (credit card test.csv). Estos conjuntos permanecerán fijos durante el desarrollo de los modelos (es decir, en este problema tampoco aplicaremos validación cruzada). En caso de que sea necesario ajustar un hiperparámetro, esto se hará evaluando la métrica de performance sobre el conjunto de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Implementar los siguientes clasificadores sobre el conjunto de datos de entrenamiento sin aplicar ninguna técnica de re-balanceo, y para cada uno reportar la matriz de confusión, accuracy, precision, recall, curva ROC y área bajo la curva ROC (AUC-ROC), curva PRC (Precision-Recall Curve) y  ́area bajo la curva PRC (AU-PRC) sobre el conjunto de validación:\n",
    "\n",
    " - Red neuronal densamente conectada con una capa oculta de 16 nodos y función de activación sigmoide. Entrenar durante 150 epochs utilizando el optimizador ADAM con un learning rate de 0.001 y un batch size de 2048, y la entrop ́ıa cruzada binaria como función de costo. Si quiere explorar diferentes configuraciones, y quedarse con la mejor, lo puede hacer.\n",
    "Opcional: Implementar la técnica de “Early Stopping” monitoreando AU-PRC (área bajo la curva Precision-Recall) con una paciencia de 10 epochs.\n",
    "\n",
    " - Bosque aleatorio (Random Forest) con 20 árboles, utilizando la entropía como criterio de división, estableciendo una profundidad máxima de 10 para cada árbol. Si quiere explorar diferentes configuraciones, y quedarse con la mejor, lo puede hacer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "Volver a entrenar ambos modelos (red neuronal y bosque aleatorio), aplicando cada una de las siguientes técnicas de re-balanceo. Para cada modelo, y cada tecnica de re-balanceo, reportar las métricas de performance mencionadas en el inciso anterior.\n",
    "\n",
    " - Undersampling: eliminar muestras de la clase mayoritaria de manera aleatoria hasta que ambas clases tengan igual proporción.\n",
    "\n",
    " - Oversampling by duplication: duplicar muestras de la clase minoritaria de manera aleatoria, hasta que que ambas clases tengan igual proporción.\n",
    "\n",
    " - Cost re-weighting: en la función de costo, multiplicar los terminos que dependen de las muestras de la clase minoritaria por un factor $C = \\frac{\\pi _2} {\\pi _1}$\n",
    " - SMOTE (Synthetic Minority Oversampling Technique): hasta que ambas clases tengan igual proporción.\n",
    " - Opcional: Explorar distintas configuraciones de red neuronal (diferente nu ́mero de capas, unidades ocultas, optimizador, learning rate, batch size) y/o del bosque aleatorio y reportar cual cree que es “el mejor”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "Sea un problema de clasifiación binaria, donde el proceso estoca ́stico que genera los datos tiene una distribución a posteriori $P(Cj/x)$ tal que para N suficientemente grande las clases no son linealmente separables en el espacio de features (es decir, las muestras de las dos clases tienen algun grado de solapamiento cuando son proyectadas sobre el espacio de features). Sean $π1 = P(C1)$ y $π2 = P(C2)$ las probabilidades marginales de que el proceso genere una muestra de la clase 1 y la clase 2, respectivamente, explicar por qué si utilizamos regresión logística binaria, sin aplicar ninguna técnica de re-balanceo, a medida que $π1$ tiende a 0 y con $N$ suficientemente grande, el accuracy tiende a 1 mientras que el precision tiende a 0.\n",
    "\n",
    "NOTA: Este resultado es general, y aplica a cualquier clasificador “no-sezgado” (como los que vimos en clase), no solamente a regresión log ́ıstica.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
